{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./social_media_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(STOPWORDS)\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in simple_preprocess(text):\n",
    "        if token not in stop_words:\n",
    "            result.append(str(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      15 non-null     int64 \n",
      " 1   text    15 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 368.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/tdt2syhd0pz2jlrzt4xbw6f00000gn/T/ipykernel_12778/3327359917.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.comments=newComments\n"
     ]
    }
   ],
   "source": [
    "# comments = df['comments'].apply(preprocess)\n",
    "newComments = []\n",
    "for i in (df.text):\n",
    "    newComments.append(preprocess(str(i)))\n",
    "df.comments=newComments\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "doc2bow expects an array of unicode tokens on input, not a single string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# comments = df['comments'].apply(preprocess)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m comments\u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mtext\n\u001b[0;32m----> 3\u001b[0m dictionary \u001b[39m=\u001b[39m corpora\u001b[39m.\u001b[39;49mDictionary(comments)\n\u001b[1;32m      4\u001b[0m corpus \u001b[39m=\u001b[39m [dictionary\u001b[39m.\u001b[39mdoc2bow(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m comments]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/corpora/dictionary.py:78\u001b[0m, in \u001b[0;36mDictionary.__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_nnz \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m documents \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_documents(documents, prune_at\u001b[39m=\u001b[39;49mprune_at)\n\u001b[1;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m     80\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m         msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbuilt \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_docs\u001b[39m}\u001b[39;00m\u001b[39m documents (total \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_pos\u001b[39m}\u001b[39;00m\u001b[39m corpus positions)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     82\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/corpora/dictionary.py:204\u001b[0m, in \u001b[0;36mDictionary.add_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    201\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39madding document #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, docno, \u001b[39mself\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[39m# update Dictionary with the document\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdoc2bow(document, allow_update\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)  \u001b[39m# ignore the result, here we only care about updating token ids\u001b[39;00m\n\u001b[1;32m    206\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mbuilt \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m documents (total \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m corpus positions)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_docs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_pos)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/corpora/dictionary.py:241\u001b[0m, in \u001b[0;36mDictionary.doc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Convert `document` into the bag-of-words (BoW) format = list of `(token_id, token_count)` tuples.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(document, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdoc2bow expects an array of unicode tokens on input, not a single string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    243\u001b[0m \u001b[39m# Construct (word, frequency) mapping.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m counter \u001b[39m=\u001b[39m defaultdict(\u001b[39mint\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: doc2bow expects an array of unicode tokens on input, not a single string"
     ]
    }
   ],
   "source": [
    "# comments = df['comments'].apply(preprocess)\n",
    "comments= df.text\n",
    "dictionary = corpora.Dictionary(comments)\n",
    "corpus = [dictionary.doc2bow(text) for text in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.038*\"hard\" + 0.034*\"like\" + 0.025*\"amazing\" + 0.024*\"whites\" + 0.023*\"working\" + 0.023*\"comments\" + 0.023*\"asians\" + 0.022*\"pity\" + 0.021*\"bitter\" + 0.021*\"muslims\"')\n",
      "(1, '0.049*\"nike\" + 0.039*\"thank\" + 0.023*\"bigger\" + 0.020*\"better\" + 0.017*\"america\" + 0.017*\"change\" + 0.017*\"black\" + 0.017*\"let\" + 0.016*\"youtube\" + 0.016*\"use\"')\n",
      "(2, '0.034*\"women\" + 0.033*\"people\" + 0.029*\"black\" + 0.029*\"like\" + 0.024*\"big\" + 0.021*\"fisto\" + 0.020*\"sports\" + 0.019*\"woman\" + 0.017*\"commercial\" + 0.016*\"world\"')\n",
      "(3, '0.064*\"rise\" + 0.059*\"like\" + 0.029*\"black\" + 0.021*\"ll\" + 0.020*\"got\" + 0.020*\"truth\" + 0.020*\"ve\" + 0.019*\"support\" + 0.013*\"history\" + 0.013*\"racism\"')\n",
      "(4, '0.029*\"mean\" + 0.026*\"wanna\" + 0.025*\"hating\" + 0.023*\"picture\" + 0.022*\"know\" + 0.022*\"people\" + 0.019*\"love\" + 0.017*\"comments\" + 0.016*\"point\" + 0.015*\"kind\"')\n",
      "(5, '0.075*\"pathetic\" + 0.035*\"think\" + 0.033*\"support\" + 0.027*\"lol\" + 0.023*\"black\" + 0.018*\"having\" + 0.016*\"culture\" + 0.016*\"time\" + 0.016*\"dollars\" + 0.016*\"typed\"')\n",
      "(6, '0.039*\"dogmeat\" + 0.025*\"isn\" + 0.025*\"nike\" + 0.023*\"reason\" + 0.021*\"supporting\" + 0.020*\"read\" + 0.020*\"hell\" + 0.020*\"fit\" + 0.019*\"critical\" + 0.019*\"helping\"')\n",
      "(7, '0.059*\"air\" + 0.046*\"max\" + 0.017*\"nike\" + 0.016*\"like\" + 0.012*\"shoe\" + 0.011*\"airmax\" + 0.011*\"right\" + 0.011*\"ve\" + 0.010*\"pair\" + 0.009*\"jordan\"')\n",
      "(8, '0.040*\"white\" + 0.028*\"black\" + 0.026*\"labor\" + 0.025*\"child\" + 0.024*\"commercial\" + 0.023*\"shoes\" + 0.019*\"stop\" + 0.019*\"talking\" + 0.018*\"seen\" + 0.016*\"terrorism\"')\n",
      "(9, '0.040*\"racist\" + 0.036*\"blacks\" + 0.023*\"person\" + 0.022*\"self\" + 0.021*\"ignorant\" + 0.018*\"comment\" + 0.018*\"nike\" + 0.014*\"color\" + 0.014*\"company\" + 0.014*\"time\"')\n"
     ]
    }
   ],
   "source": [
    "num_topics = 10\n",
    "passes = 10\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=passes)\n",
    "\n",
    "for topic in lda_model.print_topics():\n",
    "    print(topic)\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "# vis\n",
    "# vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "# # pyLDAvis.display(vis)\n",
    "# vis\n",
    "# vis = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "# pyLDAvis.save_html(vis,'lda_vis.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lda = lda_model[corpus]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
